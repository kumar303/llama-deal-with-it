# ğŸ‘ï¸

View it: https://kumar303.github.io/llama-deal-with-it/

The music is [Computer Woman by Superior Elevation](https://www.youtube.com/watch?v=eklqLkyoJWA).

# ğŸ”¥

My kids and I vibe-coded a llama dance party using [`claude-4.1-opus`](https://www.anthropic.com/). We started with this prompt:

<details>
<summary>ğŸ‘©ğŸ½â€ğŸ’» Expand</summary>

> Create a preact app using tailwind for css. Render a square centered in the viewport with slightly rounded corners. Add a diagnal dark purple to medium pink gradient to the background of the square. Add a pixelated llama in orange. Add a button, also in orange, underneath the llama that says Make the llama dance. When the button gets pressed, put "deal with it" sunglasses on the pixelated llama and make it dance up and down with crude css animation.

</details>

We prompted the rest one element at a time. The first take usually wouldn't work out well but it only took a few tries. For example, we'd say _add a hula hooping hippopotamus_ and it wouldn't get the hoop right or the arms wouldn't be connected. We'd have to ask for specific fixes like _make sure the right arm is connected at the shoulder_. The only one we gave up on was "add a [flossing](<https://en.wikipedia.org/wiki/Floss_(dance)>) lion." I don't know why that one was so hard.

Working through this project made me think a lot about LLMs (AI) for coding specifically...

# ğŸª

I admit I didn't see potential in early LLMs. All I saw were useless things like _explain how to do short division as if you're a pirate_ or halluncinations that eroded trust. Coding was even worse. Early LLMs could create simple scripts but failed to modify complex codebases.

In mid 2025, the models started getting pretty good for coding. At work I'm seeing a 1.5x to 2x speedup for coding tasks I could do by hand and a 30x speedup for those I couldn't, like when in a foreign codebase.

# â˜ï¸

Running prompts is slow and feels like the early days of dial-up Internet. In the early 90s, the Internet had obvious potential and I get the same feeling about LLMs. They will get faster at the expense of immense resource consumption (that's a topic for another day, though).

# ğŸŒ

LLMs are a tool, not a personality. When the hype dies down, we'll be left with tools not chatbots. It's way _faster_ to talk to a tool and tell it what you want but I don't need it to pretend to like me. Some of the more scary, unethical directions AI is heading towards involve impersonating humans.

# ğŸ§ 

But what if _anyone_ could build software at the speed of thought? This was always my dream as an engineer. Every skill I invested in--learning a more concise programming language (Python), mastering a keyboard layout that favored the strongest fingers (Kinesis Advantage), learning an editor that required less keystrokes (Vim!)--were all marching toward the goal of creating software at the speed of thought. LLMs provide a **massive leap** toward this goal and might even get us there.

# ğŸ’ƒğŸ¼

Everyone can build software now. I love hearing stories from designers and other non-coders who are writing code for the first time because they can explain to an LLM _how the software should behave_ as opposed to how to code it. With today's models, one still has to refine prompts to explain _how_ to build things but that might melt away as models and context techniques evolve.

# ğŸŒ´

"Are you worried about your job?" is usually what someone asks when I tell them I'm excited about AI for coding. I have 25 years experience writing code by hand, architecting and maintaining complex software, leading teams for collaboration, yadda yadda. I'm not worried. I might get paid less (lol) but I forsee software companies just **doing more** instead of reducing their workforces.

# ğŸ›

Hand written software takes a ridiculous amount of time. A small team often works for weeks or months on a feature. Hand written software has evolved a lot (publishing to the Web, practicing continuous delivery...) but it's still unbearably slow. If you've worked on software, has your team ever completed the _entire_ backlog of issues before moving on to another project? Probably not. LLM will speed up software creation but there is _so much to do_ that I'm not worried about job loss.
