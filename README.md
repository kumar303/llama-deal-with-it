# üëÅÔ∏è

View it: https://kumar303.github.io/llama-deal-with-it/

# üéµ

The music is [Computer Woman by Superior Elevation](https://www.youtube.com/watch?v=eklqLkyoJWA).

# üî•

What is it? My kids and I vibe-coded a llama dance party using [`claude-4.1-opus`](https://www.anthropic.com/). We started with this prompt:

<details>
<summary>üë©üèΩ‚Äçüíª Expand</summary>

> Create a preact app using tailwind for css. Render a square centered in the viewport with slightly rounded corners. Add a diagnal dark purple to medium pink gradient to the background of the square. Add a pixelated llama in orange. Add a button, also in orange, underneath the llama that says Make the llama dance. When the button gets pressed, put "deal with it" sunglasses on the pixelated llama and make it dance up and down with crude css animation.

</details>

We prompted the rest one element at a time. The first take usually wouldn't work out well but it only took a few tries. For example, we'd say _add a hula hooping hippopotamus_ and it wouldn't get the hoop right or the arms wouldn't be connected. We'd have to ask for specific fixes like _make sure the right arm is connected at the shoulder_ or maybe we asked to change how it looked. The only one we gave up on was "add a [flossing](<https://en.wikipedia.org/wiki/Floss_(dance)>) lion." I don't know why that one was so hard.

This project took several hours of work but would have taken weeks to code by hand. It was fun. Getting immediate results was highly motivating. Working through it made me think a lot about LLMs (AI) for coding...

# ü™ê

I admit I didn't see potential in early LLMs. All I saw were useless things like _explain how to do long division as if you're a pirate_ or halluncinations that eroded trust. Coding was even worse. Early LLMs could create simple scripts but failed to modify complex codebases for basic tasks like _move this module and update all imports_.

# ‚ú®

In mid 2025, the models started getting pretty good for coding. At work I'm seeing a 2x speedup (time to completion) for coding tasks I could easily do by hand and a 30x speedup for those I couldn't, like when in a foreign codebase or using unfamiliar libraries. While waiting for code generation, I had extra time to review other PRs or start a new task.

# ‚òéÔ∏è

Running prompts (in 2025) is slow and feels like the early days of dial-up Internet. In the 90s, the Internet had obvious potential and I get the same feeling about LLMs. They will get faster and consumers will pay. All of this will consume immense energy but that's a topic for another day.

# üåç

AI is a tool, not a personality. When the hype dies down, I hope we'll be left with more tools and less chatbots. It's way _faster_ to explain in natural language what needs doing but I don't need AI to be my friend. Some of the more scary, unethical directions AI is heading towards involve impersonating humans.

# üß†

What if _anyone_ could build software at the speed of thought? This was always my dream as an engineer. Every skill I invested in--learning a more concise programming language ([Python](https://www.python.org/)), mastering a keyboard layout that favored my stronger fingers ([Kinesis Advantage](https://kinesis-ergo.com/shop/advantage2/)), learning an editor that required less keystrokes ([Vim](https://www.vim.org/) üòÅ)--were all marching toward the goal of creating software at the speed of thought. LLMs provide a **massive leap** toward this goal and might even get us there.

# üíÉüèº

Everyone can build software now. I love hearing stories from designers and other non-coders who are writing code for the first time because they can explain to an LLM _how the software should behave_. With today's models, one still has to explain _how_ to build complex things but that will melt away as models and context techniques evolve.

# ‚úÖ

I'm not an expert in prompting but in 2025 I've had the most success when telling an LLM how to check its work. If I give it a command to run (like a failing test) or tell it to launch a browser (e.g. with [Playwright](https://playwright.dev/)) and check for a specific element on the page, it's more likely to arrive at the correct answer on its own.

# üì£

For the first time ever, I've been talking to my computer üòÇ It's faster to speak a prompt than to type it. I never bothered with dictation before since one cannot dictate computer code in a literal sense. My young kids find it more natural to speak commands at their ipads but I never really got into it until now.

# üå¥

"Are you worried about your job?" is usually what someone asks when I tell them I'm excited about AI for coding. I have 25 years experience writing code by hand, architecting and maintaining complex software, leading teams for collaboration, yadda yadda. I'm not worried. I might get paid less (lol) but I foresee software companies just **doing more** instead of reducing their workforces.

# üêõ

Hand written software takes a ridiculous amount of time. A small team often works for weeks or months on a feature. The process has evolved a lot (publishing to the Web, [continuous delivery](https://en.wikipedia.org/wiki/Continuous_delivery), [user stories](https://en.wikipedia.org/wiki/User_story)...) but it's still unbearably slow. Has your software team ever completed the _entire_ backlog of issues before moving on to another project? Probably not. LLMs will speed up software creation but there is _so much to do_ that I'm not worried about job loss.

# ‚úèÔ∏è

Rapid prototyping is the key to building usable software. Today's models are very good at it. In fact, this might be the only thing they can do with high accuracy. I've seen designers use LLMs to build fully interactive websites to demonstrate UI concepts. That's massive. Most software companies fail by simply building the wrong thing for their customers.

# üîó

What will the new abstractions look like? I'm not sure. Software abstractions like [Django](https://www.djangoproject.com/), [Rails](https://rubyonrails.org/), [jQuery](https://jquery.com/), and [React](https://react.dev/) were all created to solve some kind of hand-written sofware problem, usually around security mistakes or the tedium of boilerplate code. In Armin Ronacher's experiments with hands-off LLM code generation, he found models [wrote the best code in Go](https://lucumr.pocoo.org/2025/6/12/agentic-coding/).

# ‚ö†Ô∏è

Don't get me wrong, the AI hype right now is out of control. I find services like [Suno](https://suno.com/) that generate a song from a prompt devoid of creativity. That's not a tool, it's a rubber stamp. If it were to let me describe or, even better, _express_ a drum rhythm without having to spend 10 years mastering the drums then doing the same thing with bass guitar, keys, vocals, and letting me build _my own song_ then that would make it a tool.

# üìñ

Sal Khan [mentioned](https://www.theverge.com/decoder-podcast-with-nilay-patel/766082/khan-academy-ceo-sal-khan-ai-education-schoolhouse-hank-green-interview) how teachers protested when text books were first introduced into classrooms, fearing they'd get replaced by the text books. Teachers never went away and it's hard to imagine going to school without a physical or digital text book. When the dust settles and a few useful LLM tools remain in hand, we might think of AI more like text books.

<hr />

\~ Kumar McMillan, 2025-09-14
